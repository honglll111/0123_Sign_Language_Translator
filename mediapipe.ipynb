{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9e4f3-1bdf-4d17-a182-f7768675d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KOSA\\AppData\\Local\\Temp\\ipykernel_3136\\3580435579.py:24: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  self.client = mqtt.Client() # MQTT 클라이언트 객체 생성\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageMqttClient mqtt broker connected\n"
     ]
    }
   ],
   "source": [
    "import cv2 #OpenCV 라이브러리 사용\n",
    "import mediapipe as mp\n",
    "import paho.mqtt.client as mqtt\n",
    "import threading # 동시에 여러 작업을 수행하기 위한 기술\n",
    "import base64 # 바이너리 데이터를 텍스트로 인코딩\n",
    "\n",
    "# ImageMqttPublisher : MQTT를 통해 이미지 전송\n",
    "# init으로 클래스 초기화\n",
    "class ImageMqttPublisher: # MQTT Broker와 통신하여 이미지 전송\n",
    "    def __init__(self, brokerIp=None, brokerPort=1883, pubTopic=None):\n",
    "        # 인스턴스 변수 초기화\n",
    "        self.brokerIp = brokerIp # MQTT Broker IP주소\n",
    "        self.brokerPort = brokerPort # 포트 번호\n",
    "        self.pubTopic = pubTopic\n",
    "        self.client = None # MQTT 클라이언트 생성하고 연결할 때 사용하는 변수\n",
    "\n",
    "    # ImageMqttPublisher 클래스의 인스턴스를 MQTT 브로커에 연결\n",
    "    def connect(self):\n",
    "        thread = threading.Thread(target=self.__run, daemon=True) # daemon : 메인 프로그램이 종료될 때 자동으로 종료\n",
    "        thread.start()\n",
    "        \n",
    "    # MQTT 클라이언트를 설정하고 브로커에 연결\n",
    "    def __run(self):\n",
    "        self.client = mqtt.Client() # MQTT 클라이언트 객체 생성\n",
    "        self.client.on_connect = self.__on_connect # 연결\n",
    "        self.client.on_disconnect = self.__on_disconnect # 연결 해제\n",
    "        self.client.connect(self.brokerIp, self.brokerPort) # 브로커에 연결\n",
    "        self.client.loop_start()\n",
    "        \n",
    "    # 클라이언트가 브로커에 연결되었을 때\n",
    "    def __on_connect(self, client, userdata, flags, rc):\n",
    "        print(\"ImageMqttClient mqtt broker connected\")\n",
    "\n",
    "    # 클라이언트가 브로커와 연결이 끊어졌을 때\n",
    "    def __on_disconnect(self, client, userdata, rc):\n",
    "        print(\"ImageMqttClient mqtt broker disconnected\")\n",
    "\n",
    "    def disconnect(self):\n",
    "        self.client.loop_stop() # MQTT 클라이언트의 네트워크 루프 중지\n",
    "        self.client.disconnect() # 클라이언트와 브로커 간의 연결 해제\n",
    "\n",
    "    # ImageMqttPublisher 클래스에서 MQTT 브로커에 이미지 전송\n",
    "    def sendBase64(self, frame):\n",
    "        # 클라이언트 체크\n",
    "        if self.client is None: # MQTT 클라이언트가 초기화되지 않았다면 함수 종료\n",
    "            return\n",
    "        # 연결 상태 체크\n",
    "        if not self.client.is_connected():\n",
    "            return\n",
    "        # JPEG 포맷으로 이미지 인코딩\n",
    "        retval, bytes = cv2.imencode(\".jpg\", frame)\n",
    "        # 인코딩 실패 체크\n",
    "        if not retval:\n",
    "            print(\"image encoding fail\")\n",
    "            return\n",
    "        # Base64 문자열로 인코딩\n",
    "        b64_bytes = base64.b64encode(bytes)\n",
    "        # Base64로 인코딩된 이미지 데이터를 MQTT Broker에 보내기\n",
    "        self.client.publish(self.pubTopic, b64_bytes, retain=True)\n",
    "\n",
    "# Mediapipe 및 OpenCV 설정\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# localhost : MQTT Broker 서버 주소\n",
    "imageMqttPublisher = ImageMqttPublisher(\"localhost\", 1883, \"/camerapub\")\n",
    "imageMqttPublisher.connect()\n",
    "\n",
    "# MediaPipe Hands 설정 및 비디오 캡처 루프\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0, # 모델의 복잡도 설정\n",
    "    min_detection_confidence=0.5, # 손 검출에 대한 최소 신뢰도를 설정\n",
    "    min_tracking_confidence=0.5) as hands: # 손 추적에 대한 최소 신뢰도를 설정\n",
    "    # 비디오 캡처 장치가 열려 있는 동안 루프 실행\n",
    "    while cap.isOpened():\n",
    "        retval, frame = cap.read() # 웹캠에서 프레임 읽기\n",
    "        if not retval:\n",
    "            print(\"video capture fail\")\n",
    "            break\n",
    "\n",
    "        frame.flags.writeable = False # 성능 향상을 위해 프레임 쓰기 불가능하게 설정\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # BGR -> RGB 변환\n",
    "        results = hands.process(frame)\n",
    "\n",
    "        # 프레임 다시 쓰기 가능 설정 및 색 공간 변환\n",
    "        frame.flags.writeable = True # 프레임 다시 쓰기 가능\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR) # RGB -> BGR\n",
    "        # 손 랜드마크 그리기\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # 프레임에 손 랜드마크 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    hand_landmarks, # 그릴 랜드마크 좌표\n",
    "                    mp_hands.HAND_CONNECTIONS, # 손가락 관절 간의 연결선을 그리기 위해 사용\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(), # 랜드마크의 스타일\n",
    "                    mp_drawing_styles.get_default_hand_connections_style()) # 랜드마크 연결선의 스타일\n",
    "\n",
    "        # 보기 편하게 이미지 좌우 반전\n",
    "        cv2.imshow('MediaPipe Hands', cv2.flip(frame, 1))\n",
    "        \n",
    "        # 프레임 크기 조정\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        # 프레임을 base64 문자열로 인코딩해서 보냄\n",
    "        imageMqttPublisher.sendBase64(frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ESC 키를 누르면 종료\n",
    "            break\n",
    "\n",
    "imageMqttPublisher.disconnect()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c29b95e-e76b-44bf-b8c4-1827ec1864c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KOSA\\AppData\\Local\\Temp\\ipykernel_23848\\27163166.py:36: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  self.client = mqtt.Client()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MQTT broker connected\n",
      "InputText: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "['아프다']\n",
      "InputText: 아프다\n",
      "InputText: 아프다\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "['아프다', '막다']\n",
      "InputText: 아프다 막다\n",
      "InputText: 아프다 막다\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "['아프다', '막다', '오다']\n",
      "InputText: 아프다 막다 오다\n",
      "InputText: 아프다 막다 오다\n",
      "Dispose condition met: No landmarks for 10 seconds or only pose detected\n",
      "아프세요? 막히셨어요?\n",
      "OutputText: 아프세요? 막히셨어요?\n",
      "OutputText: 아프세요? 막히셨어요?\n",
      "MQTT broker disconnected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import paho.mqtt.client as mqtt\n",
    "import threading\n",
    "import base64\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from keras.models import load_model\n",
    "import requests\n",
    "\n",
    "# update_caption 함수 정의\n",
    "def update_caption(input_text, output_text, is_final=False):\n",
    "    if is_final:\n",
    "        # 최종 문장 (파란색으로 처리)\n",
    "        print(f\"OutputText: {output_text}\")\n",
    "    else:\n",
    "        # 중간 단어들 (검정색으로 처리)\n",
    "        print(f\"InputText: {input_text}\")\n",
    "\n",
    "# MQTT\n",
    "class ImageMqttPublisher:\n",
    "    def __init__(self, broker_ip=\"localhost\", broker_port=1883, pub_topic_image=\"/camerapub\", pub_topic_text=\"/textpub\"):\n",
    "        self.broker_ip = broker_ip\n",
    "        self.broker_port = broker_port\n",
    "        self.pub_topic_image = pub_topic_image\n",
    "        self.pub_topic_text = pub_topic_text\n",
    "        self.client = None\n",
    "\n",
    "    def connect(self):\n",
    "        thread = threading.Thread(target=self._run, daemon=True)\n",
    "        thread.start()\n",
    "\n",
    "    def _run(self):\n",
    "        self.client = mqtt.Client()\n",
    "        self.client.on_connect = self._on_connect\n",
    "        self.client.on_disconnect = self._on_disconnect\n",
    "        self.client.on_message = self._on_message  # 메시지 수신 콜백 설정\n",
    "        self.client.connect(self.broker_ip, self.broker_port)\n",
    "        self.client.loop_forever()\n",
    "\n",
    "    def _on_connect(self, client, userdata, flags, rc):\n",
    "        print(\"MQTT broker connected\")\n",
    "        self.send_initial_empty_list()\n",
    "        self.client.subscribe(self.pub_topic_text)  # 메시지 구독\n",
    "\n",
    "    def _on_disconnect(self, client, userdata, rc):\n",
    "        print(\"MQTT broker disconnected\")\n",
    "\n",
    "    def _on_message(self, client, userdata, message):\n",
    "        # 메시지 수신 처리\n",
    "        self.on_message_arrived(message)\n",
    "\n",
    "    def on_message_arrived(self, message):\n",
    "        # 메시지 처리 로직\n",
    "        message_text = message.payload.decode().strip()\n",
    "\n",
    "        # 접두어로 최종 문장을 구분\n",
    "        if message_text.startswith(\"FINAL_OUTPUT:\"):\n",
    "            output_text = message_text.replace(\"FINAL_OUTPUT:\", \"\").strip()\n",
    "            update_caption(\"\", output_text, is_final=True)\n",
    "        else:\n",
    "            input_text = message_text\n",
    "            update_caption(input_text, \"\", is_final=False)\n",
    "\n",
    "    def disconnect(self):\n",
    "        if self.client:\n",
    "            self.client.disconnect()\n",
    "\n",
    "    def send_base64(self, frame):\n",
    "        if self.client is None or not self.client.is_connected():\n",
    "            return\n",
    "        retval, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        if not retval:\n",
    "            print(\"Image encoding failed\")\n",
    "            return\n",
    "        b64_bytes = base64.b64encode(buffer)\n",
    "        self.client.publish(self.pub_topic_image, b64_bytes, retain=True)\n",
    "\n",
    "    def send_text(self, text):\n",
    "        if self.client is None or not self.client.is_connected():\n",
    "            return\n",
    "        self.client.publish(self.pub_topic_text, text, retain=True)\n",
    "    \n",
    "    def send_initial_empty_list(self):\n",
    "        if self.client is None or not self.client.is_connected():\n",
    "            return\n",
    "        self.client.publish(self.pub_topic_text, \"\", retain=True)\n",
    "\n",
    "# Mediapipe\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2BGR), results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    pose_landmarks = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    pose_connections = [\n",
    "        (0, 2), (0, 5), (2, 7), (5, 8), (11, 12), (11, 23),\n",
    "        (12, 24), (23, 24), (11, 13), (13, 15), (12, 14), (14, 16)\n",
    "    ]\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        for connection in pose_connections:\n",
    "            start_idx, end_idx = connection\n",
    "            start_landmark = results.pose_landmarks.landmark[start_idx]\n",
    "            end_landmark = results.pose_landmarks.landmark[end_idx]\n",
    "            h, w, _ = image.shape\n",
    "            x1, y1 = int(start_landmark.x * w), int(start_landmark.y * h)\n",
    "            x2, y2 = int(end_landmark.x * w), int(end_landmark.y * h)\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.circle(image, (x1, y1), 3, (255, 0, 255), -1)\n",
    "            cv2.circle(image, (x2, y2), 3, (255, 0, 255), -1)\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    return image, results\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    if results.pose_landmarks and (results.left_hand_landmarks or results.right_hand_landmarks):\n",
    "        pose_landmarks = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "        pose = np.array([[results.pose_landmarks.landmark[idx].x, results.pose_landmarks.landmark[idx].y] for idx in pose_landmarks]).flatten() if results.pose_landmarks else np.zeros(13 * 2)\n",
    "        lh = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "        rh = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "        return np.concatenate([pose, lh, rh])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def send_llama(input_text, mqtt_publisher=None):\n",
    "    url = 'https://274f-35-185-159-118.ngrok-free.app/generate'\n",
    "    \n",
    "    instruction = \"You are a patient, sick person because you were sick. You receive medical treatment at the hospital. Explain where you are sick.\"\n",
    "    \n",
    "    data = {\n",
    "        'instruction': instruction,\n",
    "        'input': input_text\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        response_data = response.json()\n",
    "        if response.status_code == 200:\n",
    "            output_text = response_data['output']\n",
    "            print(output_text)\n",
    "            if mqtt_publisher:\n",
    "                mqtt_publisher.send_text(f\"FINAL_OUTPUT: {output_text}\")\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            print(response_data['error'])\n",
    "    except requests.exceptions.JSONDecodeError:\n",
    "        print(\"Failed to decode JSON response\")\n",
    "        print(response.text)\n",
    "\n",
    "def main():\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    mqtt_publisher = ImageMqttPublisher()\n",
    "    mqtt_publisher.connect()\n",
    "\n",
    "    model = keras.models.load_model('fcn-model-reference-wang2017-0100-0.9591.keras')\n",
    "    actions = {0: 'CT', 1: '가끔', 2: '가능', 3: '가다', 4: '간(신체)', 5: '간호사', 6: '감사(고마움)', 7: '갑자기', 8: '걱정', 9: '건강', 10: '걷다(걸음)', 11: '검사(검진)', 12: '결과(결말)', 13: '계속', 14: '고생', 15: '곳', 16: '관절', 17: '괜찮다', 18: '그냥', 19: '그러면', 20: '그런데', 21: '근육', 22: '기능', 23: '기억', 24: '꼭', 25: '끝', 26: '나', 27: '나쁘다', 28: '나오다', 29: '날(시간)', 30: '남다', 31: '너무', 32: '노력', 33: '높다', 34: '느낌', 35: '다니다', 36: '다음', 37: '다치다', 38: '다행', 39: '달다(맛)', 40: '당뇨', 41: '더', 42: '동안(시간)', 43: '되다', 44: '듣다', 45: '디스크', 46: '따로', 47: '때(시간)', 48: '때문에', 49: '떨어지다', 50: '또(and)', 51: '마시다', 52: '마음', 53: '막다', 54: '만(어미)', 55: '만나다', 56: '만들다', 57: '만약', 58: '많다', 59: '맞다(옳다)', 60: '먹다', 61: '면(어미)', 62: '모두', 63: '모르다', 64: '몸', 65: '못하다', 66: '무엇', 67: '문제', 68: '바꾸다', 69: '바쁘다', 70: '방문', 71: '변하다', 72: '병(질병)', 73: '병원', 74: '보다(구경)', 75: '보통', 76: '부작용', 77: '부족', 78: '부탁', 79: '부터', 80: '불편', 81: '비교', 82: '사라지다', 83: '사용', 84: '사진', 85: '상관(관여)없다', 86: '상태', 87: '생각', 88: '생기다', 89: '선생님', 90: '설명', 91: '수술', 92: '술(주류)', 93: '쉽다', 94: '시간', 95: '시작', 96: '심장', 97: '심하다', 98: '아니다', 99: '아니면', 100: '아마', 101: '아직', 102: '아침', 103: '아프다', 104: '안과(전문)', 105: '안내', 106: '안녕', 107: '안되다', 108: '알다', 109: '암', 110: '약(물질)', 111: '어떻게', 112: '어렵다', 113: '어지럽다', 114: '없다', 115: '예약', 116: '오다', 117: '오래', 118: '요즘', 119: '우리(나의무리)', 120: '우선', 121: '운동', 122: '움직이다', 123: '원래', 124: '원인', 125: '원하다', 126: '이유', 127: '이해', 128: '일(업무)', 129: '입원', 130: '있다', 131: '잘', 132: '잠깐', 133: '저녁', 134: '전(시간에)', 135: '점수', 136: '정도', 137: '정상(제대로)', 138: '조금', 139: '조심', 140: '조절', 141: '좋다', 142: '주다', 143: '주사(행동)', 144: '줄이다', 145: '중(가운데)', 146: '중요', 147: '증상', 148: '지금', 149: '지내다', 150: '진행', 151: '집', 152: '참다', 153: '충분', 154: '치료', 155: '콩팥', 156: '특별', 157: '편하다', 158: '피', 159: '필요', 160: '필요없다', 161: '하다', 162: '하루', 163: '함께', 164: '항상', 165: '해(하다)보다', 166: '허리', 167: '혈당', 168: '확인', 169: '환자', 170: '회복', 171: '후', 172: '힘들다'}\n",
    "\n",
    "    sequence = []\n",
    "    sentence = []\n",
    "    threshold = 0.8\n",
    "\n",
    "    tracker = LandmarkTracker()\n",
    "\n",
    "    with mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while True:\n",
    "            if video_capture.isOpened():\n",
    "                ret, frame = video_capture.read()\n",
    "                if not ret:\n",
    "                    print(\"Video capture failed\")\n",
    "                    break\n",
    "    \n",
    "                # Draw landmarks\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "    \n",
    "                # Check if dispose condition is met\n",
    "                if tracker.dispose(results):\n",
    "                    print(\"Dispose condition met: No landmarks for 10 seconds or only pose detected\")\n",
    "                    break\n",
    "    \n",
    "                # Extract keypoints\n",
    "                draw_styled_landmarks(image, results)\n",
    "    \n",
    "                keypoints = extract_keypoints(results)\n",
    "                if keypoints is not None:\n",
    "                    sequence.append(keypoints)\n",
    "                    sequence = sequence[-30:]\n",
    "    \n",
    "                    if len(sequence) == 30:\n",
    "                        res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                        predicted_action = actions[np.argmax(res)]\n",
    "    \n",
    "                        if res[np.argmax(res)] > threshold:\n",
    "                            if len(sentence) > 0 and predicted_action != sentence[-1]:\n",
    "                                sentence.append(predicted_action)\n",
    "                            elif not sentence:\n",
    "                                sentence.append(predicted_action)\n",
    "    \n",
    "                            if len(sentence) > 10:\n",
    "                                sentence = sentence[-10:]\n",
    "    \n",
    "                            # 중간 단어 전송 (검정색으로 표시될 단어들)\n",
    "                            if \"FINAL_OUTPUT:\" not in ' '.join(sentence):\n",
    "                                mqtt_publisher.send_text(' '.join(sentence))  # 중간 단어들을 전송합니다.\n",
    "                                print(sentence)\n",
    "                                sequence = []\n",
    "                            \n",
    "                            # 최종 문장 전송 (Llama 모델을 통해 생성된 문장만 파란색으로 표시)\n",
    "                            if \"FINAL_OUTPUT:\" in ' '.join(sentence):\n",
    "                                final_sentence = ' '.join(sentence).replace(\"FINAL_OUTPUT:\", \"\").strip()\n",
    "                                mqtt_publisher.send_text(f\"FINAL_OUTPUT: {final_sentence}\")  # Llama에서 생성된 최종 문장만 전송합니다.\n",
    "                                break\n",
    "    \n",
    "                mqtt_publisher.send_base64(image)\n",
    "    \n",
    "                if cv2.waitKey(10) == 27:\n",
    "                    break\n",
    "\n",
    "    send_llama(' '.join(sentence), mqtt_publisher)\n",
    "    mqtt_publisher.disconnect()\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634a2f8-4915-4c36-b1d7-24bfc00d02a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
