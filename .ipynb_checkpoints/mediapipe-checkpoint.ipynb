{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8ea5eee-8acb-422c-a37c-5ad894dbfabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KOSA\\AppData\\Local\\Temp\\ipykernel_1660\\3024646156.py:40: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  self.client = mqtt.Client()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MQTT broker connected\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step\n",
      "['오다']\n",
      "InputText: 오다\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "['오다', '곳']\n",
      "InputText: 오다 곳\n",
      "Dispose condition met: No landmarks for 10 seconds or only pose detected\n",
      "여기 왔어요\n",
      "OutputText: 여기 왔어요\n",
      "MQTT broker disconnected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import paho.mqtt.client as mqtt\n",
    "import threading\n",
    "import base64\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from keras.models import load_model\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# update_caption 함수 정의\n",
    "def update_caption(input_text, output_text, is_final=False):\n",
    "    if is_final:\n",
    "        # 최종 문장 (파란색으로 처리)\n",
    "        print(f\"OutputText: {output_text}\")\n",
    "    else:\n",
    "        # 중간 단어들 (검정색으로 처리)\n",
    "        print(f\"InputText: {input_text}\")\n",
    "\n",
    "# MQTT\n",
    "class ImageMqttPublisher:\n",
    "    def __init__(self, broker_ip=\"localhost\", broker_port=1883, pub_topic_image=\"/camerapub\", pub_topic_text=\"/textpub\"):\n",
    "        self.broker_ip = broker_ip\n",
    "        self.broker_port = broker_port\n",
    "        self.pub_topic_image = pub_topic_image\n",
    "        self.pub_topic_text = pub_topic_text\n",
    "        self.client = None\n",
    "        self.last_sent_text = \"\"  # 마지막으로 전송된 텍스트 저장\n",
    "        self.last_sent_final_output = \"\"  # 마지막으로 전송된 최종 문장 저장\n",
    "        self.final_output_sent = False  # 최종 문장이 전송되었는지 여부\n",
    "\n",
    "    def connect(self):\n",
    "        thread = threading.Thread(target=self._run, daemon=True)\n",
    "        thread.start()\n",
    "\n",
    "    def _run(self):\n",
    "        self.client = mqtt.Client()\n",
    "        self.client.on_connect = self._on_connect\n",
    "        self.client.on_disconnect = self._on_disconnect\n",
    "        self.client.on_message = self._on_message  # 메시지 수신 콜백 설정\n",
    "        self.client.connect(self.broker_ip, self.broker_port)\n",
    "        self.client.loop_forever()\n",
    "\n",
    "    def _on_connect(self, client, userdata, flags, rc):\n",
    "        print(\"MQTT broker connected\")\n",
    "        self.send_initial_empty_list()\n",
    "        self.client.subscribe(self.pub_topic_text)  # 메시지 구독\n",
    "\n",
    "    def _on_disconnect(self, client, userdata, rc):\n",
    "        print(\"MQTT broker disconnected\")\n",
    "\n",
    "    def _on_message(self, client, userdata, message):\n",
    "        self.on_message_arrived(message)\n",
    "\n",
    "    def on_message_arrived(self, message):\n",
    "        message_text = message.payload.decode().strip()\n",
    "        if message_text.startswith(\"FINAL_OUTPUT:\"):\n",
    "            output_text = message_text.replace(\"FINAL_OUTPUT:\", \"\").strip()\n",
    "            update_caption(\"\", output_text, is_final=True)\n",
    "        else:\n",
    "            input_text = message_text\n",
    "            update_caption(input_text, \"\", is_final=False)\n",
    "\n",
    "    def disconnect(self):\n",
    "        if self.client:\n",
    "            self.client.disconnect()\n",
    "\n",
    "    def send_text(self, text, is_final=False):\n",
    "        if self.client is None or not self.client.is_connected():\n",
    "            return\n",
    "\n",
    "        # 최종 문장이 이미 전송된 이후에는 중간 단어 전송을 막음\n",
    "        if self.final_output_sent and not is_final:\n",
    "            return\n",
    "\n",
    "        # 중복된 텍스트인지 확인\n",
    "        if is_final:\n",
    "            if text == self.last_sent_final_output:\n",
    "                return  # 중복된 최종 문장인 경우 전송하지 않음\n",
    "            self.last_sent_final_output = text  # 최종 문장 업데이트\n",
    "            self.final_output_sent = True  # 최종 문장 전송 플래그 설정\n",
    "        else:\n",
    "            if text == self.last_sent_text:\n",
    "                return  # 중복된 중간 텍스트인 경우 전송하지 않음\n",
    "            self.last_sent_text = text  # 중간 텍스트 업데이트\n",
    "\n",
    "        self.client.publish(self.pub_topic_text, text, retain=True)\n",
    "\n",
    "    def send_base64(self, frame):\n",
    "        if self.client is None or not self.client.is_connected():\n",
    "            return\n",
    "        retval, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        if not retval:\n",
    "            print(\"Image encoding failed\")\n",
    "            return\n",
    "        b64_bytes = base64.b64encode(buffer)\n",
    "        self.client.publish(self.pub_topic_image, b64_bytes, retain=True)\n",
    "\n",
    "    def send_initial_empty_list(self):\n",
    "        if self.client is None or not self.client.is_connected():\n",
    "            return\n",
    "        self.client.publish(self.pub_topic_text, \"\", retain=True)\n",
    "\n",
    "# 20초 동안 pose만 잡히거나 아무것도 안 잡히면 멈추는 것\n",
    "class LandmarkTracker:\n",
    "    def __init__(self):\n",
    "        self.last_landmark_time = time.time()\n",
    "        self.timeout_seconds = 10\n",
    "\n",
    "    def dispose(self, results):\n",
    "        current_time = time.time()\n",
    "\n",
    "        # Check if no landmarks are detected at all\n",
    "        no_landmarks_detected = (\n",
    "            results.pose_landmarks is None and \n",
    "            results.left_hand_landmarks is None and \n",
    "            results.right_hand_landmarks is None\n",
    "        )\n",
    "\n",
    "        # Check if only pose landmarks are detected but not both hand landmarks\n",
    "        pose_only_detected = (\n",
    "            results.pose_landmarks and \n",
    "            not (results.left_hand_landmarks and results.right_hand_landmarks)\n",
    "        )\n",
    "\n",
    "        # If no landmarks detected, check the timeout\n",
    "        if no_landmarks_detected or pose_only_detected:\n",
    "            if current_time - self.last_landmark_time > self.timeout_seconds:\n",
    "                return True  # 20 seconds passed without landmarks\n",
    "        else:\n",
    "            self.last_landmark_time = current_time  # Reset timer when landmarks are detected\n",
    "\n",
    "        return False  # Continue processing\n",
    "\n",
    "# Mediapipe\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2BGR), results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    pose_landmarks = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    pose_connections = [\n",
    "        (0, 2), (0, 5), (2, 7), (5, 8), (11, 12), (11, 23),\n",
    "        (12, 24), (23, 24), (11, 13), (13, 15), (12, 14), (14, 16)\n",
    "    ]\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        for connection in pose_connections:\n",
    "            start_idx, end_idx = connection\n",
    "            start_landmark = results.pose_landmarks.landmark[start_idx]\n",
    "            end_landmark = results.pose_landmarks.landmark[end_idx]\n",
    "            h, w, _ = image.shape\n",
    "            x1, y1 = int(start_landmark.x * w), int(start_landmark.y * h)\n",
    "            x2, y2 = int(end_landmark.x * w), int(end_landmark.y * h)\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.circle(image, (x1, y1), 3, (255, 0, 255), -1)\n",
    "            cv2.circle(image, (x2, y2), 3, (255, 0, 255), -1)\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    return image, results\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    if results.pose_landmarks and (results.left_hand_landmarks or results.right_hand_landmarks):\n",
    "        pose_landmarks = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "        pose = np.array([[results.pose_landmarks.landmark[idx].x, results.pose_landmarks.landmark[idx].y] for idx in pose_landmarks]).flatten() if results.pose_landmarks else np.zeros(13 * 2)\n",
    "        lh = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "        rh = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "        return np.concatenate([pose, lh, rh])\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def send_llama(input_text, mqtt_publisher=None):\n",
    "    url = 'https://7d8d-34-142-240-196.ngrok-free.app/generate'\n",
    "    \n",
    "    instruction = \"You are a patient, sick person because you were sick. You receive medical treatment at the hospital. Explain where you are sick.\"\n",
    "    \n",
    "    data = {\n",
    "        'instruction': instruction,\n",
    "        'input': input_text\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        response_data = response.json()\n",
    "        if response.status_code == 200:\n",
    "            output_text = response_data['output']\n",
    "            print(output_text)\n",
    "            if mqtt_publisher:\n",
    "                mqtt_publisher.send_text(f\"FINAL_OUTPUT: {output_text}\")\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            print(response_data['error'])\n",
    "    except requests.exceptions.JSONDecodeError:\n",
    "        print(\"Failed to decode JSON response\")\n",
    "        print(response.text)\n",
    "        \n",
    "def main():\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    mqtt_publisher = ImageMqttPublisher()\n",
    "    mqtt_publisher.connect()\n",
    "\n",
    "    model = keras.models.load_model('fcn-model-reference-wang2017-0100-0.9591.keras')\n",
    "    actions = {0: 'CT', 1: '가끔', 2: '가능', 3: '가다', 4: '간(신체)', 5: '간호사', 6: '감사(고마움)', 7: '갑자기', 8: '걱정', 9: '건강', 10: '걷다(걸음)', 11: '검사(검진)', 12: '결과(결말)', 13: '계속', 14: '고생', 15: '곳', 16: '관절', 17: '괜찮다', 18: '그냥', 19: '그러면', 20: '그런데', 21: '근육', 22: '기능', 23: '기억', 24: '꼭', 25: '끝', 26: '나', 27: '나쁘다', 28: '나오다', 29: '날(시간)', 30: '남다', 31: '너무', 32: '노력', 33: '높다', 34: '느낌', 35: '다니다', 36: '다음', 37: '다치다', 38: '다행', 39: '달다(맛)', 40: '당뇨', 41: '더', 42: '동안(시간)', 43: '되다', 44: '듣다', 45: '디스크', 46: '따로', 47: '때(시간)', 48: '때문에', 49: '떨어지다', 50: '또(and)', 51: '마시다', 52: '마음', 53: '막다', 54: '만(어미)', 55: '만나다', 56: '만들다', 57: '만약', 58: '많다', 59: '맞다(옳다)', 60: '먹다', 61: '면(어미)', 62: '모두', 63: '모르다', 64: '몸', 65: '못하다', 66: '무엇', 67: '문제', 68: '바꾸다', 69: '바쁘다', 70: '방문', 71: '변하다', 72: '병(질병)', 73: '병원', 74: '보다(구경)', 75: '보통', 76: '부작용', 77: '부족', 78: '부탁', 79: '부터', 80: '불편', 81: '비교', 82: '사라지다', 83: '사용', 84: '사진', 85: '상관(관여)없다', 86: '상태', 87: '생각', 88: '생기다', 89: '선생님', 90: '설명', 91: '수술', 92: '술(주류)', 93: '쉽다', 94: '시간', 95: '시작', 96: '심장', 97: '심하다', 98: '아니다', 99: '아니면', 100: '아마', 101: '아직', 102: '아침', 103: '아프다', 104: '안과(전문)', 105: '안내', 106: '안녕', 107: '안되다', 108: '알다', 109: '암', 110: '약(물질)', 111: '어떻게', 112: '어렵다', 113: '어지럽다', 114: '없다', 115: '예약', 116: '오다', 117: '오래', 118: '요즘', 119: '우리(나의무리)', 120: '우선', 121: '운동', 122: '움직이다', 123: '원래', 124: '원인', 125: '원하다', 126: '이유', 127: '이해', 128: '일(업무)', 129: '입원', 130: '있다', 131: '잘', 132: '잠깐', 133: '저녁', 134: '전(시간에)', 135: '점수', 136: '정도', 137: '정상(제대로)', 138: '조금', 139: '조심', 140: '조절', 141: '좋다', 142: '주다', 143: '주사(행동)', 144: '줄이다', 145: '중(가운데)', 146: '중요', 147: '증상', 148: '지금', 149: '지내다', 150: '진행', 151: '집', 152: '참다', 153: '충분', 154: '치료', 155: '콩팥', 156: '특별', 157: '편하다', 158: '피', 159: '필요', 160: '필요없다', 161: '하다', 162: '하루', 163: '함께', 164: '항상', 165: '해(하다)보다', 166: '허리', 167: '혈당', 168: '확인', 169: '환자', 170: '회복', 171: '후', 172: '힘들다'}\n",
    "\n",
    "    sequence = []\n",
    "    sentence = []\n",
    "    threshold = 0.8\n",
    "\n",
    "    tracker = LandmarkTracker()\n",
    "\n",
    "    with mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while True:\n",
    "            if video_capture.isOpened():\n",
    "                ret, frame = video_capture.read()\n",
    "                if not ret:\n",
    "                    print(\"Video capture failed\")\n",
    "                    break\n",
    "    \n",
    "                # Draw landmarks\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "    \n",
    "                # Check if dispose condition is met\n",
    "                if tracker.dispose(results):\n",
    "                    print(\"Dispose condition met: No landmarks for 10 seconds or only pose detected\")\n",
    "                    break\n",
    "    \n",
    "                # Extract keypoints\n",
    "                draw_styled_landmarks(image, results)\n",
    "    \n",
    "                keypoints = extract_keypoints(results)\n",
    "                if keypoints is not None:\n",
    "                    sequence.append(keypoints)\n",
    "                    sequence = sequence[-30:]\n",
    "    \n",
    "                    if len(sequence) == 30:\n",
    "                        res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                        predicted_action = actions[np.argmax(res)]\n",
    "    \n",
    "                        if res[np.argmax(res)] > threshold:\n",
    "                            if len(sentence) > 0 and predicted_action != sentence[-1]:\n",
    "                                sentence.append(predicted_action)\n",
    "                            elif not sentence:\n",
    "                                sentence.append(predicted_action)\n",
    "    \n",
    "                            if len(sentence) > 10:\n",
    "                                sentence = sentence[-10:]\n",
    "    \n",
    "                            # 중간 단어 전송 (검정색으로 표시될 단어들)\n",
    "                            if \"FINAL_OUTPUT:\" not in ' '.join(sentence):\n",
    "                                mqtt_publisher.send_text(' '.join(sentence))  # 중간 단어들을 전송합니다.\n",
    "                                print(sentence)\n",
    "                                sequence = []\n",
    "                            \n",
    "                            # 최종 문장 전송 (Llama 모델을 통해 생성된 문장만 파란색으로 표시)\n",
    "                            if \"FINAL_OUTPUT:\" in ' '.join(sentence):\n",
    "                                final_sentence = ' '.join(sentence).replace(\"FINAL_OUTPUT:\", \"\").strip()\n",
    "                                mqtt_publisher.send_text(f\"FINAL_OUTPUT: {final_sentence}\", is_final=True)  # Llama에서 생성된 최종 문장만 전송합니다.\n",
    "                                break\n",
    "    \n",
    "                mqtt_publisher.send_base64(image)\n",
    "    \n",
    "                if cv2.waitKey(10) == 27:\n",
    "                    break\n",
    "\n",
    "    send_llama(' '.join(sentence), mqtt_publisher)\n",
    "    mqtt_publisher.disconnect()\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae179a-35ab-4a9e-8918-2331860052fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
